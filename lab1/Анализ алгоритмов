1. Сортировка выбором
Алгоритм сортировки выбором относится к классу простых методов сортировки, используемых главным образом для демонстрации основ сортировки и анализа временных характеристик алгоритмов. 
Общий принцип работы алгоритма сортировки выбором:
Алгоритм состоит из двух основных этапов:
1)выбор: Алгоритм последовательно выбирает минимальный элемент из неотсортированной части массива и ставит его в начало этой части.
2)обмен: Минимальный элемент меняется местами с первым элементом неотсортированной части массива.
Эти шаги повторяются до тех пор, пока весь массив не будет отсортирован.

Сложность алгоритма в нотации BIG(O): O(n²)
Давайте разберём, почему временная сложность этого алгоритма равна O(n²):
Внешний цикл выполняется (n−1) раз, поскольку последняя итерация не нужна (элемент уже стоит на своём месте).
Внутренний цикл также просматривает всё остающееся подмножество массива на каждом этапе, то есть на первой итерации он смотрит (n-1) элементов, на следующей (n-2), и так далее.

2. Сортировка обменом (пузырек)
Алгоритм сортировки выбором работает следующим образом:
1) последовательно проходят по списку элементов, сравнивая соседние пары
2) если пара расположена неправильно (левый элемент больше правого), элементы меняют местами
3) проходы продолжаются до тех пор, пока весь список не будет отсортирован

Скрипт включает 4 ключевые части:

Класс SelectionSortExample — контейнер для нашего метода сортировки и вспомогательных функций.
Метод selectionSort(int[] array) — основной алгоритм сортировки, принимающий массив и сортирующий его методом выбора.
Метод printArray(int[] array) — вспомогательная функция для вывода содержимого массива на экран.
Метод main(String[] args) — главная точка входа приложения, инициализирует массив и запускает алгоритм сортировки.

Временная сложность алгоритма сортировки выбором в худшем, среднем и лучшем случаях составляет O(n²).

3. Сортировка вставками
Алгоритм сортировки вставками принадлежит к простым и наглядным способам сортировки. Его идея заключается в постепенном расширении отсортированной области массива путём вставки новых элементов на правильные места внутри неё.
Общая логика работы алгоритма:
Изначально рассматривается первый элемент массива как отдельная отсортированная последовательность.Постепенно берётся очередной элемент массива, и алгоритм пытается вставить его в уже отсортированную часть массива на соответствующее место.Чтобы освободить место для вставки, элементы в отсортированной части массива смещаются вправо, создавая пустое пространство для нового элемента.Повторяя этот процесс для каждого элемента, получаем полностью отсортированный массив.

Сложность алгоритма O(n²) — в худшем и среднем случаях, однако в наилучшем случае (если массив почти отсортирован) его производительность близка к линейному времени O(n).

4. Сортировка слиянием
Алгоритм сортировки слиянием ("Merge Sort") основан на подходе «разделяй и властвуй»: массив сначала делится на отдельные небольшие части, каждая из которых затем сортируется отдельно, а потом все части объединяются в единый отсортированный массив. Рассмотрим поэтапно, как это реализуется.

Общая структура работы алгоритма:
-Массив делится на две части
-Обе части рекурсивно сортируются
-Два отсортированных участка сливаются в один общий отсортированный массив
Реализация построена вокруг двух ключевых процедур:

1)процедура разделения и рекурсии (mergeSort): рекурсивно делит массив на маленькие части.
2)процедура слияния (merge): объединяет две отсортированные части в единую отсортированную последовательность.

Временная сложность (оценка Big-O):
Время на разделение: Каждое разбиение уменьшает размер массива вдвое, что ведет к глубине рекурсии O(log n)
Время на слияние: Каждая операция слияния двух частей занимает линейное время O(n), так как приходится пройти по обоим массивам целиком.
Таким образом, временная сложность алгоритма сортировки слиянием оценивается как O(n log n) в любом сценарии (лучшем, среднем и худшем случае)

5. Сортировка Шелла
Общая схема работы:
-алгоритм сортировки Шелла похож на улучшенную версию сортировки вставками. Отличие в том, что элементы сначала рассматриваются на большем расстоянии, а затем это расстояние уменьшается, пока не достигнет единицы.
   Механизм сортировки:
 1)Первоначально выбирается большой интервал (gap), и элементы, находящиеся на таком расстоянии друг от друга, сортируются методами вставок.
 2)Потом интервал уменьшается (обычно вдвое), и эта процедура повторяется.
 3)Такой подход ускоряет процесс сортировки, позволяя быстро приблизить массив к состоянию полного порядка.
   Детали работы алгоритма:
*Интервал (gap): начальный интервал равен длине массива, делённой на 2. В дальнейшем он постоянно уменьшается.
*Прохождение массива: при заданном интервале группы элементов сортируются подобно методу вставок.
*Сравнение и сдвиг: если текущий элемент меньше, чем предыдущий (рассматриваемый с учётом интервала), он смещается назад, занимая подходящую позицию.

Временная сложность алгоритма сортировки Шелла сильно зависит от выбора начальных интервалов (gap sequence). Например, для последовательности интервалов наподобие [N/2,N/4,...,1] средняя временная сложность может достигать O(n^3/2). Но существуют оптимальные последовательности интервалов, позволяющие снизить сложность до O(n(log n )^2) или даже ближе к O(n log n).

6. Быстрая сортировка
1)Функция quicksort(arr):
  Принцип работы основан на механизме "разделяй и властвуй": выбирается опорный элемент (pivot), а затем элементы распределяются на две подгруппы — меньшие и большие относительно pivot.
2)Базовый случай (len(arr) <= 1):
  Если массив пуст или содержит единственный элемент, он уже отсортирован, и мы возвращаем его как есть.
3)Выбор опорного элемента (pivot):
Опорный элемент выбирается из средней позиции массива, чтобы минимизировать вероятность дисбаланса в подмассивах.
4)Создание трёх категорий элементов:
  -Все элементы, меньшие pivot, собираются в список less.
  -Все элементы, равные pivot, попадают в список equal.
  -Все элементы, большие pivot, идут в список greater.
5)Рекурсивная сортировка:
  Оба подмассива (меньших и больших элементов) рекурсивно сортируются с помощью той же функции.
  Результатом является соединение отсортированных подмассивов с центральной частью, содержащей элементы, равные pivot.


Лучшая ситуация: если подмассивы равномерно сбалансированы, то быстродействие достигает оптимальной сложности O(n log n).

Средняя ситуация: средняя временная сложность также остается O(n log n ), так как большинство реализаций обеспечивают хороший баланс.

Худшая ситуация: в редких случаях (при плохом выборе pivot) возможна деградация до O(n^2), если массив уже отсортирован или почти отсортирован.

7. Пирамидальная сортировка
 
 Принцип работы:
-Пирамидальная сортировка базируется на структуре бинарной кучи. Бинарная куча представляет собой полное двоичное дерево, которое удовлетворяет условию кучи: значение любого узла не меньше (или не больше) значений его дочерних узлов.
Сначала массив преобразуется в max-кучу, а затем из нее последовательно извлекают максимальное значение и отправляют его в конец массива.
 Детали процесса:
*Heapify (корректировка структуры):
Процедура выстраивает дерево так, чтобы поддерживать свойства кучи.
*Build Heap (строительство кучи):
Вся исходная структура массива переделывается в valid max-кучу, проводя операцию heapify для всех родителей.
*Extract Max (извлечение максимального элемента):
Максимальный элемент (корень) отправляется в конец массива, а на его место подставляется последний элемент, после чего дерево заново корректируется процедурой heapify.

Временная сложность пирамидальной сортировки = O(n log n) для любого сценария (среднее, лучшее и худшее случаи).

8. Последовательный поиск

Принцип работы:
-линейный поиск представляет собой наиболее простую стратегию поиска элемента в коллекции.
Идея заключается в том, чтобы последовательно проверять каждый элемент списка, пока не встретится искомое значение или пока не закончится просмотр списка.
Порядок действий:
*В нашем примере создается список чисел.
*Пользователь вводит значение для поиска (в данном случае оно заранее определено как 7).
*Скрипт начинает проверку элементов, начиная с первого.
*Как только обнаруживается совпадение, немедленно прекращается дальнейшее сканирование и возвращается индекс соответствующего элемента.

Лучшая ситуация: Если искомый элемент расположен в самом начале списка, то потребуется одна проверка — временная сложность O(1).

Средняя ситуация: В большинстве случаев придется просмотреть значительную часть списка, что дает среднюю оценку O(n/2), которую принято округлять до O(n).

Худшая ситуация: Если элемент вообще отсутствует или находится в самом конце списка, понадобится проверить абсолютно все элементы — временная сложность O(n).

9. Бинарный (двоичный, дихотомический) поиск

  Принцип работы:
Бинарный поиск возможен только на предварительно отсортированных данных.
Суть алгоритма сводится к последовательному делению области поиска надвое и сравнению с центральным элементом.
   Процесс поиска:
-Устанавливаем начальные границы поиска: нижняя (low) и верхняя (high).
-На каждой итерации вычисляем центр области (mid), сравниваем его с искомым значением.
-Если центральный элемент равен искомому, поиск успешен.
-Если центральный элемент больше цели, значит, интересующая нас область находится слева от центра.
-Если центральный элемент меньше цели, искомая область располагается справа от центра.

Лучшие ситуации: Если элемент находится в середине или близко к центру, достаточно одной-двух проверок — сложность O(1).

Средняя ситуация: Логарифмический рост, так как на каждой итерации диапазон поиска сокращается вдвое — сложность O(log n).

Худшая ситуация: Даже если элемент находится последним или вовсе отсутствует, число итераций ограничено высотой бинарного дерева — это снова O(log n).

10. Интерполирующий поиск

  Интерполирующий поиск улучшает классический бинарный поиск, учитывая равномерность распределения элементов в массиве.
Вместо строгого деления пополам, алгоритм делает предположение о вероятном местонахождении элемента на основе пропорций значений.
  Последовательность действий:
1)Устанавливаем начальные границы поиска (low и high).
2)Вычисляем новое предполагаемое местоположение (pos) на основе разницы между крайними значениями и целевым значением.
3)Если элемент найден, возвращаем его индекс.
4)Если нет, уточняем границы поиска ( если элемент меньше ожидаемого, диапазон сужается влево, если элемент больше ожидаемого, диапазон сужается вправо) и повторяем попытку.
5)Функция printArray(const std::vector<int>& arr) - выводит элементы массива на экран.

Лучшая ситуация: Если массив идеально равномерно распределён, временная сложность может достигнуть O(log(log n)).

Средняя ситуация: В среднем ожидается сложность O(log n), что сравнимо с бинарным поиском.

Худшая ситуация: Если распределение неравномерное или плохо подобранный элемент, возможно ухудшение до O(n).

11. Поиск по Фибоначчи

  Принцип работы:
Поиск по Фибоначчи использует специальную технику деления массива на отрезки, размеры которых соответствуют числам Фибоначчи.
Сначала находим ближайшее число Фибоначчи, превышающее длину массива, и виртуально дополняем массив до этого размера.
Проводим последовательные сокращения областей поиска, ориентируясь на отношения соседних чисел Фибоначчи.
  Подробности работы:
-Вычисляются три последних числа Фибоначчи (F[m-2], F[m-1], F[m]), и с их помощью формируется диапазон поиска.
-Для каждого шага рассчитываем индекс потенциально правильного кандидата, проверяя его на соответствие цели.
-Если элемент не найден, повторяем расчёт и сокращаем область поиска, пока не исчерпаем возможные варианты.

Временная сложность: O(log n)

    --Выполнил студент Савельев Иван из группы ПИ01--



